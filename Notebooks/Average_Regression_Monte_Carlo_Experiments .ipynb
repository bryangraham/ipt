{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte carlo  experiments for average regression\n",
    "##### _Bryan S. Graham, UC - Berkeley, bgraham@econ.berkeley.edu_\n",
    "##### _Cristine Pinto, FGV, cristinepinto@gmail.com_\n",
    "\n",
    "\n",
    "This notebook includes replication code for the Monte Carlo experiments reports in Graham and Pinto (2018). In addition to several standard Python scientific computing libraries, we use functions from the **ipt** library. This library is available on GitHub at https://github.com/bryangraham/ipt. It includes implementations of Wooldridge's (2004) generalized inverse probability weighting estimator for average partial effects (APE), the \"Oaxaca-Blinder\" type APE estimator described in the paper, as well as of our own locally efficient, doubly robust estimator.\n",
    "<br>\n",
    "<br>\n",
    "### References   \n",
    "\n",
    "Graham, Bryan S. and Pinto, Cristine Campose de Xavier. (2018). \"Semiparametrically efficient estimation of the average linear regression function,\" CEMMAP Working Paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Python to plot all figures inline (i.e., not in a separate window)\n",
    "%matplotlib inline\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append location of ipt module base directory to system path\n",
    "# NOTE: only required if permanent install of ipt package not made\n",
    "import sys\n",
    "sys.path.append('/Users/bgraham/Dropbox/Sites/software/ipt/')\n",
    "\n",
    "# Load ipt module\n",
    "import ipt as ipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"runtime\", RuntimeWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider four designs, each described in detail in Graham and Pinto (2018). In all cases the conditional distribution $ f(X|W) $ is poisson with a conditional mean of $\\exp\\left(k\\left(W\\right)'\\phi\\right)$. In designs $1$ and $3$ the $k\\left(W\\right)$ vector includes a constant and a linear term. In designs $2$ and $4$ a quadratic term is also included.    \n",
    "<br>\n",
    "<br>\n",
    "The outcome variable is generated according to $Y=a\\left(W\\right)+b\\left(W\\right)X+U$. In the first two designs $a\\left(W\\right)$ and $b\\left(W\\right)$ are linear functions of $W$, while in the last two they are quadratic functions. Both $W$ and $U$ are standard normal random variables, uncorrelated with each other. The parameter values are chosen such that the standard error of a semiparametrically efficient estimator would 0.05 across each design (when $N = 1,000$). In this sense each design is equally difficult.    \n",
    "<br>\n",
    "<br>\n",
    "We evaluate the performance of three estimators: (i) the generalized inverse probability weight estimator introduced by Wooldridge (2004), (ii) the \"Oaxaca-Blinder\" imputation type estimator discussed in the paper, and (iii) our own locally efficient doubly robust estimator.    \n",
    "<br>\n",
    "<br>\n",
    "For the Wooldridge (2004) estimator $ f(X|W) $ is modelled as a Poisson distribution with a conditional mean of $\\exp\\left(k\\left(W\\right)'\\phi\\right)$ with $k\\left(W\\right)$ including a constant and linear term. The Wooldridge (2004) estimator is consistent in designs 1 and 3. The \"Oaxaca-Blinder\" estimator assumes that both $a\\left(W\\right)$ and $b\\left(W\\right)$ are linear functions of $W$. This estimator will be consistent in designs $1$ and $2$.    \n",
    "<br>\n",
    "<br>\n",
    "Our doubly robust estimator is based on the same submodels as the Wooldridge (2004) and \"Oaxaca-Blinder\" ones. It is consistent across designs $1$, $2$ and $3$. It is locally efficient in design $1$.    \n",
    "<br>\n",
    "<br>\n",
    "All three estimators are inconsistent in design $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating design 1 of 4\n",
      "Time required f/ MC rep  1000 of 5000: 9.050674200057983\n",
      "Time required f/ MC rep  2000 of 5000: 9.621357917785645\n",
      "Time required f/ MC rep  3000 of 5000: 8.74156904220581\n",
      "Time required f/ MC rep  4000 of 5000: 8.931617975234985\n",
      "Time required f/ MC rep  5000 of 5000: 7.9779651165008545\n",
      "Simulating design 2 of 4\n",
      "Time required f/ MC rep  1000 of 5000: 7.480386972427368\n",
      "Time required f/ MC rep  2000 of 5000: 7.772614002227783\n",
      "Time required f/ MC rep  3000 of 5000: 7.612371921539307\n",
      "Time required f/ MC rep  4000 of 5000: 7.337346076965332\n",
      "Time required f/ MC rep  5000 of 5000: 7.358033180236816\n",
      "Simulating design 3 of 4\n",
      "Time required f/ MC rep  1000 of 5000: 7.548329830169678\n",
      "Time required f/ MC rep  2000 of 5000: 7.845314025878906\n",
      "Time required f/ MC rep  3000 of 5000: 7.717278957366943\n",
      "Time required f/ MC rep  4000 of 5000: 7.744146823883057\n",
      "Time required f/ MC rep  5000 of 5000: 8.39312481880188\n",
      "Simulating design 4 of 4\n",
      "Time required f/ MC rep  1000 of 5000: 7.989760875701904\n",
      "Time required f/ MC rep  2000 of 5000: 7.780302047729492\n",
      "Time required f/ MC rep  3000 of 5000: 7.946007013320923\n",
      "Time required f/ MC rep  4000 of 5000: 8.499834775924683\n",
      "Time required f/ MC rep  5000 of 5000: 7.3344810009002686\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "N = 1000\n",
    "S = 5000\n",
    "\n",
    "# List with a, b, c and efficiency bounds for each design\n",
    "D1 = [[1, 1, 0], [2, 1.22, 0], [0.1, 0.5, 0], [0.05]]\n",
    "D2 = [[1, 1, 0], [2, 1.26, 0], [0.1, 0.5, 0.1], [0.05]]\n",
    "D3 = [[1, 1, 0.5], [2, 1, 0.5], [0.1, 0.5, 0], [0.05]]\n",
    "D4 = [[1, 1, 0.5], [2, 1.05, 0.5], [0.1, 0.5, 0.1], [0.05]]\n",
    "\n",
    "Designs = [D1, D2, D3, D4]\n",
    "\n",
    "NumDesigns = len(Designs)\n",
    "\n",
    "# Initialize matrices to store Monte Carlo results\n",
    "bias     = np.zeros((S,3*NumDesigns))\n",
    "coverage = np.zeros((S,3*NumDesigns))\n",
    "se       = np.zeros((S,3*NumDesigns))\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(361)\n",
    "\n",
    "d = 0\n",
    "start = time.time()\n",
    "for Design in Designs:\n",
    "    \n",
    "    print(\"Simulating design \" + str(d+1) + \" of \" + str(len(Designs)))\n",
    "    \n",
    "    a = Design[0]\n",
    "    b = Design[1]\n",
    "    c = Design[2]\n",
    "    asym_se = Design[3][0]\n",
    "      \n",
    "    for s in range(0,S):\n",
    "       \n",
    "        # Simulate s-th dataset\n",
    "        W, U = np.random.multivariate_normal([0,0], [[1, 0], [0, 1]], N).T\n",
    "        X    = np.random.poisson(np.exp(c[0] + c[1]*W + c[2]*W**2))\n",
    "        Y    = ((a[0] + a[2]) + a[1]*W + a[2]*(W**2 - 1)) + ((b[0] + b[2]) + b[1]*W + b[2]*(W**2 - 1))*X + U\n",
    "    \n",
    "        W = pd.DataFrame(W, columns=['W'])    \n",
    "        X = pd.Series(X, name = 'X')  \n",
    "        Y = pd.Series(Y, name = 'Y')\n",
    "    \n",
    "        # Doubly robust estimator\n",
    "        [beta_hat_dr, vcov_beta_hat_dr] = ipt.avreg_dr(Y, X, W, psmodel='poisson', c_id=None, s_wgt=None, \\\n",
    "                                                       silent=True)\n",
    "        \n",
    "        # Wooldridge (2004) estimator\n",
    "        [beta_hat_ipw, vcov_beta_hat_ipw] = ipt.avreg_ipw(Y, X, W, psmodel='poisson', c_id=None, s_wgt=None, \\\n",
    "                                                        silent=True)\n",
    "        \n",
    "        # \"Oaxaca-Blinder\" estimator\n",
    "        [beta_hat_ob, vcov_beta_hat_ob] = ipt.avreg_ob(Y, X, W, c_id=None, s_wgt=None, \\\n",
    "                                                       silent=True)\n",
    "        \n",
    "        bias[s,[d,d+NumDesigns,d+2*NumDesigns]]    = (beta_hat_dr[0]  - b[0] - b[2])[0], \\\n",
    "                                                     (beta_hat_ipw[0] - b[0] - b[2])[0], \\\n",
    "                                                     (beta_hat_ob[0]  - b[0] - b[2])[0]\n",
    "    \n",
    "        # Coverage\n",
    "        coverage[s,[d,d+NumDesigns,d+2*NumDesigns]] = ((b[0] + b[2]<=beta_hat_dr[0] + 1.96*np.sqrt(vcov_beta_hat_dr[0,0]))*\\\n",
    "                                                       (b[0] + b[2]>=beta_hat_dr[0] - 1.96*np.sqrt(vcov_beta_hat_dr[0,0])))[0], \\\n",
    "                                                      ((b[0] + b[2]<=beta_hat_ipw[0] + 1.96*np.sqrt(vcov_beta_hat_ipw[0,0]))*\\\n",
    "                                                       (b[0] + b[2]>=beta_hat_ipw[0] - 1.96*np.sqrt(vcov_beta_hat_ipw[0,0])))[0], \\\n",
    "                                                      ((b[0] + b[2]<=beta_hat_ob[0] + 1.96*np.sqrt(vcov_beta_hat_ob[0,0]))*\\\n",
    "                                                       (b[0] + b[2]>=beta_hat_ob[0] - 1.96*np.sqrt(vcov_beta_hat_ob[0,0])))[0]\n",
    "           \n",
    "        # Standard error length\n",
    "        se[s,[d,d+NumDesigns,d+2*NumDesigns]]       = np.sqrt(vcov_beta_hat_dr[0,0]), \\\n",
    "                                                      np.sqrt(vcov_beta_hat_ipw[0,0]), \\\n",
    "                                                      np.sqrt(vcov_beta_hat_ob[0,0])\n",
    "    \n",
    "        end = time.time()\n",
    "        if (s+1) % 1000 == 0:\n",
    "            print(\"Time required f/ MC rep  \" + str(s+1) + \" of \" + str(S) + \": \" + str(end-start))      \n",
    "            start = time.time()\n",
    "    d += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bias\n",
      "                1 (S,S)  2 (S,R)  3 (R,S)  4 (R,R)\n",
      "DR              -0.0008   0.0017  -0.0057   0.4387\n",
      "GIPW            -0.0020  -0.2679  -0.0012   0.3027\n",
      "Oaxaca-Blinder  -0.0008   0.0013  -0.3291  -0.2155\n",
      "\n",
      "Median Bias\n",
      "                1 (S,S)  2 (S,R)  3 (R,S)  4 (R,R)\n",
      "DR               0.0001   0.0014  -0.0113   0.4123\n",
      "GIPW            -0.0008  -0.2597  -0.0018   0.2717\n",
      "Oaxaca-Blinder  -0.0003   0.0009  -0.3268  -0.2010\n",
      "\n",
      "Standard deviation\n",
      "                1 (S,S)  2 (S,R)  3 (R,S)  4 (R,R)\n",
      "DR               0.0507   0.0518   0.1099   0.2035\n",
      "GIPW             0.0853   0.1331   0.0830   0.1897\n",
      "Oaxaca-Blinder   0.0500   0.0504   0.0993   0.1571\n",
      "\n",
      "Mean Standard Error\n",
      "                1 (S,S)  2 (S,R)  3 (R,S)  4 (R,R)\n",
      "DR               0.0500   0.0566   0.1051   0.2005\n",
      "GIPW             0.0836   0.1325   0.0816   0.1360\n",
      "Oaxaca-Blinder   0.0497   0.0498   0.0937   0.1152\n",
      "\n",
      "Median Standard Error\n",
      "                1 (S,S)  2 (S,R)  3 (R,S)  4 (R,R)\n",
      "DR               0.0499   0.0561   0.0981   0.1687\n",
      "GIPW             0.0809   0.1198   0.0794   0.1216\n",
      "Oaxaca-Blinder   0.0496   0.0497   0.0899   0.1087\n",
      "\n",
      "Coverage (nominal 95%)\n",
      "                1 (S,S)  2 (S,R)  3 (R,S)  4 (R,R)\n",
      "DR               0.9450   0.9620   0.9276   0.3076\n",
      "GIPW             0.9438   0.4634   0.9436   0.4006\n",
      "Oaxaca-Blinder   0.9480   0.9442   0.0772   0.5148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print options and row and column labels for Monte Carlo results\n",
    "pd.options.display.precision=4\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "Designs = ['1 (S,S)', '2 (S,R)', '3 (R,S)', '4 (R,R)']\n",
    "Estimators    = ['DR', 'GIPW', 'Oaxaca-Blinder']\n",
    "\n",
    "# Report bias and coverage results\n",
    "print(\"Mean Bias\")\n",
    "mean_bias = pd.DataFrame(np.mean(bias, axis=0).reshape(3,NumDesigns,order='C'), columns=Designs, index=Estimators)\n",
    "print(mean_bias)\n",
    "print(\"\")\n",
    "print(\"Median Bias\")\n",
    "median_bias = pd.DataFrame(np.median(bias, axis=0).reshape(3,NumDesigns,order='C'), columns=Designs, index=Estimators)\n",
    "print(median_bias)\n",
    "print(\"\")\n",
    "print(\"Standard deviation\")\n",
    "std_dev = pd.DataFrame(np.std(bias, axis=0).reshape(3,NumDesigns,order='C'), columns=Designs, index=Estimators)\n",
    "print(std_dev)\n",
    "print(\"\")\n",
    "print(\"Mean Standard Error\")\n",
    "mean_std_err = pd.DataFrame(np.mean(se, axis=0).reshape(3,NumDesigns,order='C'), columns=Designs, index=Estimators)\n",
    "print(mean_std_err)\n",
    "print(\"\")\n",
    "print(\"Median Standard Error\")\n",
    "median_std_err = pd.DataFrame(np.median(se, axis=0).reshape(3,NumDesigns,order='C'), columns=Designs, index=Estimators)\n",
    "print(median_std_err)\n",
    "print(\"\")\n",
    "print(\"Coverage (nominal 95%)\")\n",
    "actual_cov = pd.DataFrame(np.mean(coverage, axis=0).reshape(3,NumDesigns,order='C'), columns=Designs, index=Estimators)\n",
    "print(actual_cov)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error associated with a Monte Carlo coverage estimate is $\\sqrt{\\alpha\\left(1-\\alpha\\right)/B}$. With $B = 5,000$ simulations and $\\alpha = 0.05$ this results in a standard error of approximately 0.003 or a 95 percent confidence interval of $[0.944, 0.956]$. Overall the Monte Carlo results are consistent with theoretical expectations. This is especially true when considering larger sampler sizes (as would be expected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "html {\n",
       "  font-size: 62.5% !important; }\n",
       "body {\n",
       "  font-size: 1.5em !important; /* currently ems cause chrome bug misinterpreting rems on body element */\n",
       "  line-height: 1.6 !important;\n",
       "  font-weight: 400 !important;\n",
       "  font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
       "  color: #222 !important; }\n",
       "\n",
       "div{ border-radius: 0px !important;  }\n",
       "div.CodeMirror-sizer{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_area{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "div.out_prompt_overlay:hover{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_prompt:hover{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  color: #333 !important;\n",
       "  margin-top: 0 !important;\n",
       "  margin-bottom: 2rem !important;\n",
       "  font-weight: 300 !important; }\n",
       "h1 { font-size: 4.0rem !important; line-height: 1.2 !important;  letter-spacing: -.1rem !important;}\n",
       "h2 { font-size: 3.6rem !important; line-height: 1.25 !important; letter-spacing: -.1rem !important; }\n",
       "h3 { font-size: 3.0rem !important; line-height: 1.3 !important;  letter-spacing: -.1rem !important; }\n",
       "h4 { font-size: 2.4rem !important; line-height: 1.35 !important; letter-spacing: -.08rem !important; }\n",
       "h5 { font-size: 1.8rem !important; line-height: 1.5 !important;  letter-spacing: -.05rem !important; }\n",
       "h6 { font-size: 1.5rem !important; line-height: 1.6 !important;  letter-spacing: 0 !important; }\n",
       "\n",
       "@media (min-width: 550px) {\n",
       "  h1 { font-size: 5.0rem !important; }\n",
       "  h2 { font-size: 4.2rem !important; }\n",
       "  h3 { font-size: 3.6rem !important; }\n",
       "  h4 { font-size: 3.0rem !important; }\n",
       "  h5 { font-size: 2.4rem !important; }\n",
       "  h6 { font-size: 1.5rem !important; }\n",
       "}\n",
       "\n",
       "p {\n",
       "  margin-top: 0 !important; }\n",
       "  \n",
       "a {\n",
       "  color: #1EAEDB !important; }\n",
       "a:hover {\n",
       "  color: #0FA0CE !important; }\n",
       "  \n",
       "code {\n",
       "  padding: .2rem .5rem !important;\n",
       "  margin: 0 .2rem !important;\n",
       "  font-size: 90% !important;\n",
       "  white-space: nowrap !important;\n",
       "  background: #F1F1F1 !important;\n",
       "  border: 1px solid #E1E1E1 !important;\n",
       "  border-radius: 4px !important; }\n",
       "pre > code {\n",
       "  display: block !important;\n",
       "  padding: 1rem 1.5rem !important;\n",
       "  white-space: pre !important; }\n",
       "  \n",
       "button{ border-radius: 0px !important; }\n",
       ".navbar-inner{ background-image: none !important;  }\n",
       "select, textarea{ border-radius: 0px !important; }\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This imports an attractive notebook style from Github\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen('http://bit.ly/1Bf5Hft')\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
